
			 SEMEVAL-2012 TASK 17

				 STS
		     Semantic Textual Similarity:
 
		     A Unified Framework for the
	      Evaluation of Modular Semantic Components



The test dataset contains the following:

  00-README.txt 		  this file
  00-description-of-submission.txt
                                  template file to be included with each run

  STS.input.MSRpar.txt		  tab separated input file with ids and sentence pairs
  STS.input.MSRvid.txt		   "
  STS.input.SMTeuroparl.txt	   "
  STS.input.surprise.OnWN.txt      "
  STS.input.surprise.SMTnews.txt   "

  STS.output.MSRpar.txt	  	  tab separated sample output


Introduction
------------

Given two sentences of text, s1 and s2, the systems participating in
this task should compute how similar s1 and s2 are, returning a
similarity score, and an optional confidence score.

The dataset comprises pairs of sentences drawn from the publicly
available datasets used in training:

- MSR-Paraphrase, Microsoft Research Paraphrase Corpus
  http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/
  750 pairs of sentences.

- MSR-Video, Microsoft Research Video Description Corpus
  http://research.microsoft.com/en-us/downloads/38cf15fd-b8df-477e-a4e4-a4680caa75af/
  750 pairs of sentences.

- SMTeuroparl: WMT2008 develoment dataset (Europarl section)
  http://www.statmt.org/wmt08/shared-evaluation-task.html
  459 pairs of sentences.

In addition, it contains two surprise datasets comprising the
following collections:

- SMTnews: news conversation sentence pairs from WMT
  399 pairs of sentences.

- OnWN: pairs of sentences where the first comes from Ontonotes and
  the second from a WordNet definition.
  750 pairs of sentences.


NOTE: Participant systems should NOT use the following datasets to
develop or train their systems:

- test part of MSR-Paraphrase (development and train are fine)
- the text of the videos in MSR-Video
- the data from the evaluation tasks at any WMT (all years are forbidden)



License
-------

All participants need to agree with the license terms from Microsoft Research:

http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/
http://research.microsoft.com/en-us/downloads/38cf15fd-b8df-477e-a4e4-a4680caa75af/




Input format
------------

The input file consists of two fields separated by tabs:

- first sentence (does not contain tabs)
- second sentence (does not contain tabs)

Please check any of STS.input.*.txt



Answer format
--------------

Format: the gold standard file consist of one single field per line:

- a number between 0 and 5

The answer format includes the similarity score and an optional
confidence score. Each line has two fields separated by a tab:

- a number between 0 and 5 (the similarity score)
- a number between 0 and 100 (the confidence score)

The use of confidence scores is experimental, and it is not required
for the official score.

Please check STS.MSRpar.output.txt which always returns 2.5 with
confidence 100.


Scoring
-------

The official score is based on Pearson correlation. The use of
confidence scores will be experimental, and it is not required for the
official scores.


Participation in the task
-------------------------

Participant teams will be allowed to submit three runs at most. Each
run will be delivered as a compressed file (zip format) and will contain:

- a directory
- the answer files for all datasets
- a description file (see below)

The participants are required to follow the naming conventions, as follows:

  task6-GROUP-APPROACH.zip

Containing
  
  task6-GROUP-APPROACH/
     task6-GROUP-APPROACH.description.txt
     STS.output.MSRpar.txt		 
     STS.output.MSRvid.txt		 
     STS.output.SMTeuroparl.txt	 
     STS.output.surprise.OnWN.txt    
     STS.output.surprise.SMTnews.txt 

where GROUP identifies which group made the submission

and APPROACH identifies each run. 

Each run needs to be accompanied by a text file describing the method,
tools and resources used in the run. This file will help the
organizers produce an informative report on the task. Please fill the
required information following the format in the file:

  00-description-of-submission.txt

Please check the following for further registration and participation
instructions:

- http://www.cs.york.ac.uk/semeval/task17/#registration
- http://www.cs.york.ac.uk/semeval/task17/#participation


NOTE: Participant systems should NOT use the following datasets to
develop or train their systems:

- test part of MSR-Paraphrase (development and train are fine)
- the text of the videos in MSR-Video
- the data from the evaluation tasks at any WMT (all years are
  forbidden)



Other
-----

Please check http://www.cs.york.ac.uk/semeval/task17/ for more details.

We recommend that potential participants join the task mailing list:

 http://groups.google.com/group/STS-semeval



Thanks, for participating in the SemEval Semantic Textual Similarity
(STS) shared task.

Good luck!
      
 STS Organizers

Eneko Agirre
Daniel Cer
Mona Diab
Bill Dolan 


